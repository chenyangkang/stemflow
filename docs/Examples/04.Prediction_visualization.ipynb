{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Visualization\n",
    "\n",
    "Yangkang Chen<br>\n",
    "Sep 12, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyangkang/miniforge3/envs/stemflow_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please download the sample data from:\n",
    "# https://figshare.com/articles/dataset/Sample_data_Mallard_csv/24080745\n",
    "# Assuming now it's downloaded and saved as './Sample_data_Mallard.csv'\n",
    "\n",
    "# you can also try other species like \n",
    "# https://figshare.com/articles/dataset/Sample_data_Alder_Flycatcher_csv/24080751\n",
    "# https://figshare.com/articles/dataset/Sample_data_Short-eared_Owl_csv/24080742\n",
    "# https://figshare.com/articles/dataset/Sample_data_Eurasian_Tree_Sparrow_csv/24080748\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please also download the sample prediction set here:\n",
    "# https://figshare.com/articles/dataset/Predset_2020_csv/24124980\n",
    "# Assuming now it's downloaded and saved as './Predset_2020.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'./Sample_data_Mallard.csv')\n",
    "data = data.drop('sampling_event_identifier', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('count', axis=1)\n",
    "y = data['count'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First thing first: Spatio-temporal train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemflow.model_selection import ST_train_test_split\n",
    "X_train, X_test, y_train, y_test = ST_train_test_split(X, y, \n",
    "                                                       Spatio_blocks_count = 50, Temporal_blocks_count=50,\n",
    "                                                       random_state=42, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AdaSTEM hurdle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemflow.model.AdaSTEM import AdaSTEM, AdaSTEMClassifier, AdaSTEMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from stemflow.model.Hurdle import Hurdle_for_AdaSTEM, Hurdle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hurdle_for_AdaSTEM(\n",
    "    classifier=AdaSTEMClassifier(base_model=XGBClassifier(tree_method='hist',random_state=42, verbosity = 0, n_jobs=1),\n",
    "                                save_gridding_plot = True,\n",
    "                                ensemble_fold=10, \n",
    "                                min_ensemble_required=7,\n",
    "                                grid_len_lon_upper_threshold=50,\n",
    "                                grid_len_lon_lower_threshold=5,\n",
    "                                grid_len_lat_upper_threshold=50,\n",
    "                                grid_len_lat_lower_threshold=5,\n",
    "                                points_lower_threshold=50,\n",
    "                                temporal_start = 1,\n",
    "                                temporal_end=366,\n",
    "                                temporal_step=20,\n",
    "                                temporal_bin_interval = 50,\n",
    "                                Spatio1='longitude',\n",
    "                                Spatio2 = 'latitude', \n",
    "                                Temporal1 = 'DOY',\n",
    "                                use_temporal_to_train=True,\n",
    "                                njobs=4),\n",
    "    regressor=AdaSTEMRegressor(base_model=XGBRegressor(tree_method='hist',random_state=42, verbosity = 0, n_jobs=1),\n",
    "                                save_gridding_plot = True,\n",
    "                                ensemble_fold=10, \n",
    "                                min_ensemble_required=7,\n",
    "                                grid_len_lon_upper_threshold=50,\n",
    "                                grid_len_lon_lower_threshold=5,\n",
    "                                grid_len_lat_upper_threshold=50,\n",
    "                                grid_len_lat_lower_threshold=5,\n",
    "                                points_lower_threshold=20,\n",
    "                                temporal_start = 1, \n",
    "                                temporal_end=366,\n",
    "                                temporal_step=20, \n",
    "                                temporal_bin_interval = 50,\n",
    "                                Spatio1='longitude',\n",
    "                                Spatio2 = 'latitude', \n",
    "                                Temporal1 = 'DOY',\n",
    "                                use_temporal_to_train=True,\n",
    "                                njobs=4)\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Ensemble: 100%|██████████| 10/10 [00:52<00:00,  5.29s/it]\n",
      "100%|██████████| 44131/44131 [06:05<00:00, 120.82it/s] \n",
      "Generating Ensemble: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
      "100%|██████████| 16237/16237 [04:51<00:00, 55.68it/s]  \n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train.reset_index(drop=True), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./01.demo_adastem_model.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting ensemble 0 : 100%|██████████| 4297/4297 [00:03<00:00, 1202.10it/s]\n",
      "predicting ensemble 1 : 100%|██████████| 4420/4420 [00:05<00:00, 875.39it/s] \n",
      "predicting ensemble 2 : 100%|██████████| 4762/4762 [00:04<00:00, 1107.83it/s]\n",
      "predicting ensemble 3 : 100%|██████████| 4664/4664 [00:03<00:00, 1220.38it/s]\n",
      "predicting ensemble 4 : 100%|██████████| 3818/3818 [00:03<00:00, 1079.67it/s]\n",
      "predicting ensemble 5 : 100%|██████████| 5053/5053 [00:03<00:00, 1456.68it/s]\n",
      "predicting ensemble 6 : 100%|██████████| 4732/4732 [00:03<00:00, 1368.79it/s]\n",
      "predicting ensemble 7 : 100%|██████████| 3910/3910 [00:03<00:00, 1227.59it/s]\n",
      "predicting ensemble 8 : 100%|██████████| 4726/4726 [00:03<00:00, 1341.99it/s]\n",
      "predicting ensemble 9 : 100%|██████████| 3749/3749 [00:02<00:00, 1312.92it/s]\n",
      "predicting ensemble 0 : 100%|██████████| 1441/1441 [00:01<00:00, 867.51it/s]\n",
      "predicting ensemble 1 : 100%|██████████| 1392/1392 [00:01<00:00, 828.50it/s] \n",
      "predicting ensemble 2 : 100%|██████████| 1567/1567 [00:02<00:00, 774.88it/s]\n",
      "predicting ensemble 3 : 100%|██████████| 1564/1564 [00:01<00:00, 931.53it/s] \n",
      "predicting ensemble 4 : 100%|██████████| 1913/1913 [00:01<00:00, 1081.96it/s]\n",
      "predicting ensemble 5 : 100%|██████████| 1795/1795 [00:01<00:00, 1001.74it/s]\n",
      "predicting ensemble 6 : 100%|██████████| 1339/1339 [00:01<00:00, 953.53it/s] \n",
      "predicting ensemble 7 : 100%|██████████| 1395/1395 [00:01<00:00, 898.81it/s] \n",
      "predicting ensemble 8 : 100%|██████████| 1995/1995 [00:01<00:00, 1155.56it/s]\n",
      "predicting ensemble 9 : 100%|██████████| 1836/1836 [00:01<00:00, 919.49it/s] \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage not predictable 3.54%\n"
     ]
    }
   ],
   "source": [
    "perc = np.sum(np.isnan(pred.flatten()))/len(pred.flatten())\n",
    "print(f'Percentage not predictable {round(perc*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'y_true':y_test.flatten(),\n",
    "    'y_pred':np.where(pred.flatten()<0, 0, pred.flatten())\n",
    "}).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.6997116842800103,\n",
       " 'kappa': 0.44340693396590547,\n",
       " 'f1': 0.5236919349578344,\n",
       " 'precision': 0.610338835794961,\n",
       " 'recall': 0.45858833129334964,\n",
       " 'average_precision': 0.3709106059034073,\n",
       " 'Spearman_r': 0.45977487977714604,\n",
       " 'Pearson_r': 0.24042235520294966,\n",
       " 'R2': 0.006236435298972665,\n",
       " 'MAE': 4.131342386356913,\n",
       " 'MSE': 1537.3664676260294,\n",
       " 'poisson_deviance_explained': 0.2181041180794966}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaSTEM.eval_STEM_res('hurdle', pred_df.y_true, pred_df.y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_set = pd.read_csv('./Predset_2020.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce the prediction size\n",
    "pred_set['lng_grid'] = np.digitize(\n",
    "    pred_set.longitude,\n",
    "    np.linspace(-180,180,500)\n",
    ")\n",
    "\n",
    "pred_set['lat_grid'] = np.digitize(\n",
    "    pred_set.latitude,\n",
    "    np.linspace(-90,90,500)\n",
    ")\n",
    "\n",
    "pred_set = pred_set.sample(frac=1, replace=False).groupby(['lng_grid','lat_grid']).first().reset_index(drop=True)\n",
    "# pred_set = pred_set.drop(['lng_grid','lat_grid'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [2:11:16<00:00, 21.52s/it]  \n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for doy in tqdm(range(1,367)):\n",
    "    pred_set['DOY'] = doy\n",
    "    pred_set['duration_minutes'] = 60\n",
    "    pred_set['Traveling'] = 1\n",
    "    pred_set['Stationary'] = 0\n",
    "    pred_set['Area'] = 0\n",
    "    pred_set['effort_distance_km'] = 1\n",
    "    pred_set['number_observers'] = 1\n",
    "    pred_set['obsvr_species_count'] = 500\n",
    "    pred_set['time_observation_started_minute_of_day'] = 420\n",
    "    pred = model.predict(pred_set.fillna(-1), verbosity=0)\n",
    "    pred_list.append(pred)\n",
    "    \n",
    "    not_p = np.sum(np.isnan(pred.flatten()))/len(pred.flatten())\n",
    "    # print(f'DOY {doy} Not predictable: {not_p*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = []\n",
    "for doy,doy_pred in enumerate(pred_list):\n",
    "    pred_df.append(pd.DataFrame({\n",
    "        'longitude':pred_set.longitude.values,\n",
    "        'latitude':pred_set.latitude.values,\n",
    "        'DOY':doy,\n",
    "        'pred':np.array(doy_pred).flatten()\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat(pred_df, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemflow.utils.plot_gif import make_sample_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0.0.0.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.95.96.97.98.99.100.101.102.103.104.105.106.107.108.109.110.111.112.113.114.115.116.117.118.119.120.121.122.123.124.125.126.127.128.129.130.131.132.133.134.135.136.137.138.139.140.141.142.143.144.145.146.147.148.149.150.151.152.153.154.155.156.157.158.159.160.161.162.163.164.165.166.167.168.169.170.171.172.173.174.175.176.177.178.179.180.181.182.183.184.185.186.187.188.189.190.191.192.193.194.195.196.197.198.199.200.201.202.203.204.205.206.207.208.209.210.211.212.213.214.215.216.217.218.219.220.221.222.223.224.225.226.227.228.229.230.231.232.233.234.235.236.237.238.239.240.241.242.243.244.245.246.247.248.249.250.251.252.253.254.255.256.257.258.259.260.261.262.263.264.265.266.267.268.269.270.271.272.273.274.275.276.277.278.279.280.281.282.283.284.285.286.287.288.289.290.291.292.293.294.295.296.297.298.299.300.301.302.303.304.305.306.307.308.309.310.311.312.313.314.315.316.317.318.319.320.321.322.323.324.325.326.327.328.329.330.331.332.333.334.335.336.337.338.339.340.341.342.343.344.345.346.347.348.349.350.351.352.353.354.355.356.357.358.359.360.361.362.363.364.365.\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "make_sample_gif(pred_df, './pred_gif.gif',\n",
    "                            col='pred', log_scale = True,\n",
    "                            Spatio1='longitude', Spatio2='latitude', Temporal1='DOY',\n",
    "                            figsize=(18,9), xlims=(-180, 180), ylims=(-90,90), grid=True,\n",
    "                            xtick_interval=20, ytick_interval=20,\n",
    "                            lng_size = 360, lat_size = 180, dpi=300, fps=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Predicted Results](../pred_gif.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-09-12T17:19:50.691903+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.5\n",
      "IPython version      : 8.15.0\n",
      "\n",
      "Compiler    : Clang 15.0.7 \n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "stemflow    : 0.0.8\n",
      "numpy       : 1.25.2\n",
      "scipy       : 1.11.2\n",
      "pandas      : 2.1.0\n",
      "xgboost     : 2.0.0\n",
      "tqdm        : 4.66.1\n",
      "matplotlib  : 3.7.3\n",
      "h3pandas    : 0.2.4\n",
      "geopandas   : 0.13.2\n",
      "scikit-learn: 1.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from watermark import watermark\n",
    "print(watermark())\n",
    "print(watermark(packages=\"stemflow,numpy,scipy,pandas,xgboost,tqdm,matplotlib,h3pandas,geopandas,scikit-learn\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
