{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = 'Eurasian_Tree_Sparrow'\n",
    "year=2010\n",
    "\n",
    "with open(f'./test_data/sp_data/Eurasian_Tree_Sparrow/Eurasian_Tree_Sparrow_{year}.pkl','rb') as f:\n",
    "    sp_data = pickle.load(f)\n",
    "    \n",
    "checklist_data = pd.read_csv(f'./test_data/checklist_data/checklist_data_filtered_{year}.csv')\n",
    "prediction_data = pd.read_csv(f'./test_data/prediction_set/prediction_set_gridlen10_{year}_ERA_bios.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_data = checklist_data.merge(sp_data, on='sampling_event_identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h3_05',\n",
       " 'DOY',\n",
       " 'year',\n",
       " 'time_observation_started_bin',\n",
       " 'sampling_event_identifier',\n",
       " 'duration_minutes',\n",
       " 'protocol_type',\n",
       " 'Traveling',\n",
       " 'Stationary',\n",
       " 'Area',\n",
       " 'effort_distance_km',\n",
       " 'number_observers',\n",
       " 'time_observation_started',\n",
       " 'observation_date',\n",
       " 'country',\n",
       " 'locality_id',\n",
       " 'observer_id',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'obsvr_species_count',\n",
       " 'group_identifier',\n",
       " 'species_count',\n",
       " 'elevation_mean',\n",
       " 'slope_mean',\n",
       " 'eastness_mean',\n",
       " 'northness_mean',\n",
       " 'elevation_std',\n",
       " 'slope_std',\n",
       " 'eastness_std',\n",
       " 'northness_std',\n",
       " 'tmax_daily',\n",
       " 'tmin_daily',\n",
       " 'prec_daily',\n",
       " 'bio1',\n",
       " 'bio2',\n",
       " 'bio3',\n",
       " 'bio4',\n",
       " 'bio5',\n",
       " 'bio6',\n",
       " 'bio7',\n",
       " 'bio8',\n",
       " 'bio9',\n",
       " 'bio10',\n",
       " 'bio11',\n",
       " 'bio12',\n",
       " 'bio13',\n",
       " 'bio14',\n",
       " 'bio15',\n",
       " 'bio16',\n",
       " 'bio17',\n",
       " 'bio18',\n",
       " 'bio19',\n",
       " 'closed_shrublands',\n",
       " 'closed_shrublands_ed',\n",
       " 'closed_shrublands_lpi',\n",
       " 'closed_shrublands_pd',\n",
       " 'cropland_or_natural_vegetation_mosaics',\n",
       " 'cropland_or_natural_vegetation_mosaics_ed',\n",
       " 'cropland_or_natural_vegetation_mosaics_lpi',\n",
       " 'cropland_or_natural_vegetation_mosaics_pd',\n",
       " 'croplands',\n",
       " 'croplands_ed',\n",
       " 'croplands_lpi',\n",
       " 'croplands_pd',\n",
       " 'deciduous_broadleaf_forests',\n",
       " 'deciduous_broadleaf_forests_ed',\n",
       " 'deciduous_broadleaf_forests_lpi',\n",
       " 'deciduous_broadleaf_forests_pd',\n",
       " 'deciduous_needleleaf_forests',\n",
       " 'deciduous_needleleaf_forests_ed',\n",
       " 'deciduous_needleleaf_forests_lpi',\n",
       " 'deciduous_needleleaf_forests_pd',\n",
       " 'evergreen_broadleaf_forests',\n",
       " 'evergreen_broadleaf_forests_ed',\n",
       " 'evergreen_broadleaf_forests_lpi',\n",
       " 'evergreen_broadleaf_forests_pd',\n",
       " 'evergreen_needleleaf_forests',\n",
       " 'evergreen_needleleaf_forests_ed',\n",
       " 'evergreen_needleleaf_forests_lpi',\n",
       " 'evergreen_needleleaf_forests_pd',\n",
       " 'grasslands',\n",
       " 'grasslands_ed',\n",
       " 'grasslands_lpi',\n",
       " 'grasslands_pd',\n",
       " 'mixed_forests',\n",
       " 'mixed_forests_ed',\n",
       " 'mixed_forests_lpi',\n",
       " 'mixed_forests_pd',\n",
       " 'non_vegetated_lands',\n",
       " 'non_vegetated_lands_ed',\n",
       " 'non_vegetated_lands_lpi',\n",
       " 'non_vegetated_lands_pd',\n",
       " 'open_shrublands',\n",
       " 'open_shrublands_ed',\n",
       " 'open_shrublands_lpi',\n",
       " 'open_shrublands_pd',\n",
       " 'permanent_wetlands',\n",
       " 'permanent_wetlands_ed',\n",
       " 'permanent_wetlands_lpi',\n",
       " 'permanent_wetlands_pd',\n",
       " 'savannas',\n",
       " 'savannas_ed',\n",
       " 'savannas_lpi',\n",
       " 'savannas_pd',\n",
       " 'urban_and_built_up_lands',\n",
       " 'urban_and_built_up_lands_ed',\n",
       " 'urban_and_built_up_lands_lpi',\n",
       " 'urban_and_built_up_lands_pd',\n",
       " 'water_bodies',\n",
       " 'water_bodies_ed',\n",
       " 'water_bodies_lpi',\n",
       " 'water_bodies_pd',\n",
       " 'woody_savannas',\n",
       " 'woody_savannas_ed',\n",
       " 'woody_savannas_lpi',\n",
       " 'woody_savannas_pd',\n",
       " 'entropy',\n",
       " 'month',\n",
       " 'week',\n",
       " 'time_observation_started_minute_of_day',\n",
       " 'lat',\n",
       " 'lng',\n",
       " 'count']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(checklist_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h3_05</th>\n",
       "      <th>DOY</th>\n",
       "      <th>year</th>\n",
       "      <th>time_observation_started_bin</th>\n",
       "      <th>sampling_event_identifier</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>Traveling</th>\n",
       "      <th>Stationary</th>\n",
       "      <th>Area</th>\n",
       "      <th>...</th>\n",
       "      <th>woody_savannas</th>\n",
       "      <th>woody_savannas_ed</th>\n",
       "      <th>woody_savannas_lpi</th>\n",
       "      <th>woody_savannas_pd</th>\n",
       "      <th>entropy</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>time_observation_started_minute_of_day</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8548d877fffffff</td>\n",
       "      <td>113</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>S6316193</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348832</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>840</td>\n",
       "      <td>35.818561</td>\n",
       "      <td>-106.201875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8528842bfffffff</td>\n",
       "      <td>173</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>S6569337</td>\n",
       "      <td>240.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>990</td>\n",
       "      <td>43.775556</td>\n",
       "      <td>-116.263847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85275d77fffffff</td>\n",
       "      <td>292</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>S7007864</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402941</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>440</td>\n",
       "      <td>43.005149</td>\n",
       "      <td>-88.063145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85269c1bfffffff</td>\n",
       "      <td>206</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>S6675098</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Area</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126931</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>450</td>\n",
       "      <td>39.048907</td>\n",
       "      <td>-108.521381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85262c83fffffff</td>\n",
       "      <td>143</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>S6462985</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214559</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>450</td>\n",
       "      <td>44.748870</td>\n",
       "      <td>-92.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>852aa847fffffff</td>\n",
       "      <td>311</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>S7081446</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.776426</td>\n",
       "      <td>0.776426</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>900</td>\n",
       "      <td>38.871790</td>\n",
       "      <td>-76.984847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>8529ae0bfffffff</td>\n",
       "      <td>37</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>S5877755</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Area</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>540</td>\n",
       "      <td>35.669000</td>\n",
       "      <td>-118.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>8548c933fffffff</td>\n",
       "      <td>263</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>S6908849</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1092</td>\n",
       "      <td>35.875628</td>\n",
       "      <td>-111.413040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>8544cc0ffffffff</td>\n",
       "      <td>360</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>S7313006</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>0.388213</td>\n",
       "      <td>0.388213</td>\n",
       "      <td>1.103277</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>900</td>\n",
       "      <td>34.576196</td>\n",
       "      <td>-84.919252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>85489e27fffffff</td>\n",
       "      <td>355</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>S7296536</td>\n",
       "      <td>480.0</td>\n",
       "      <td>Area</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654670</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>510</td>\n",
       "      <td>30.452550</td>\n",
       "      <td>-97.770744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  h3_05  DOY  year  time_observation_started_bin  \\\n",
       "0       8548d877fffffff  113  2010                             2   \n",
       "1       8528842bfffffff  173  2010                             3   \n",
       "2       85275d77fffffff  292  2010                             1   \n",
       "3       85269c1bfffffff  206  2010                             1   \n",
       "4       85262c83fffffff  143  2010                             1   \n",
       "...                 ...  ...   ...                           ...   \n",
       "399995  852aa847fffffff  311  2010                             2   \n",
       "399996  8529ae0bfffffff   37  2010                             2   \n",
       "399997  8548c933fffffff  263  2010                             3   \n",
       "399998  8544cc0ffffffff  360  2010                             2   \n",
       "399999  85489e27fffffff  355  2010                             2   \n",
       "\n",
       "       sampling_event_identifier  duration_minutes protocol_type  Traveling  \\\n",
       "0                       S6316193              20.0    Stationary          0   \n",
       "1                       S6569337             240.0    Stationary          0   \n",
       "2                       S7007864              17.0     Traveling          1   \n",
       "3                       S6675098              60.0          Area          0   \n",
       "4                       S6462985             150.0     Traveling          1   \n",
       "...                          ...               ...           ...        ...   \n",
       "399995                  S7081446              50.0     Traveling          1   \n",
       "399996                  S5877755             120.0          Area          0   \n",
       "399997                  S6908849               8.0    Stationary          0   \n",
       "399998                  S7313006              25.0     Traveling          1   \n",
       "399999                  S7296536             480.0          Area          0   \n",
       "\n",
       "        Stationary  Area  ...  woody_savannas  woody_savannas_ed  \\\n",
       "0                1     0  ...        0.000000           0.000000   \n",
       "1                1     0  ...        0.000000           0.000000   \n",
       "2                0     0  ...        0.000000           0.000000   \n",
       "3                0     1  ...        0.000000           0.000000   \n",
       "4                0     0  ...        0.000000           0.000000   \n",
       "...            ...   ...  ...             ...                ...   \n",
       "399995           0     0  ...        0.555556          41.666667   \n",
       "399996           0     1  ...        0.000000           0.000000   \n",
       "399997           1     0  ...        0.000000           0.000000   \n",
       "399998           0     0  ...        0.416667          27.777778   \n",
       "399999           0     1  ...        0.000000           0.000000   \n",
       "\n",
       "       woody_savannas_lpi woody_savannas_pd   entropy month week  \\\n",
       "0                0.000000          0.000000  0.348832     4   16   \n",
       "1                0.000000          0.000000 -0.000000     6   25   \n",
       "2                0.000000          0.000000  0.402941    10   42   \n",
       "3                0.000000          0.000000  0.126931     7   29   \n",
       "4                0.000000          0.000000  0.214559     5   20   \n",
       "...                   ...               ...       ...   ...  ...   \n",
       "399995           0.776426          0.776426  0.999370    11   44   \n",
       "399996           0.000000          0.000000 -0.000000     2    5   \n",
       "399997           0.000000          0.000000 -0.000000     9   38   \n",
       "399998           0.388213          0.388213  1.103277    12   51   \n",
       "399999           0.000000          0.000000  0.654670    12   51   \n",
       "\n",
       "        time_observation_started_minute_of_day        lat         lng  \n",
       "0                                          840  35.818561 -106.201875  \n",
       "1                                          990  43.775556 -116.263847  \n",
       "2                                          440  43.005149  -88.063145  \n",
       "3                                          450  39.048907 -108.521381  \n",
       "4                                          450  44.748870  -92.802100  \n",
       "...                                        ...        ...         ...  \n",
       "399995                                     900  38.871790  -76.984847  \n",
       "399996                                     540  35.669000 -118.306000  \n",
       "399997                                    1092  35.875628 -111.413040  \n",
       "399998                                     900  34.576196  -84.919252  \n",
       "399999                                     510  30.452550  -97.770744  \n",
       "\n",
       "[400000 rows x 122 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checklist_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "class MyMaxEntropy(object):\n",
    "    def __init__(self, lr=0.0001):\n",
    "        \"\"\"\n",
    "        最大熵模型的实现，为了方便理解，尽可能的将参数都存储为字典形式\n",
    "        :param lr: 学习率，默认值为0.0001\n",
    "\n",
    "        其他参数：\n",
    "        :param w: 模型的参数，字典\n",
    "        :param N: 样本数量\n",
    "        :param label: 标签空间\n",
    "        :param hat_p_x: 边缘分布P(X)的经验分布\n",
    "        :param hat_p_x_y: 联合分布P(X,Y)的经验分布\n",
    "        :param E_p: 特征函数f(x,y)关于模型P(X|Y)与经验分布hatP(X)的期望值\n",
    "        :param E_hat_p: 特征函数f(x,y)关于经验分布hatP(X,Y)的期望值\n",
    "        :param eps: 一个接近于0的正数极小值，这个值放在log的计算中，防止报错\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.params = {'w': None}\n",
    "\n",
    "        self.N = None\n",
    "        self.label = None\n",
    "\n",
    "        self.hat_p_x = {}\n",
    "        self.hat_p_x_y = {}\n",
    "\n",
    "        self.E_p = {}\n",
    "        self.E_hat_p = {}\n",
    "\n",
    "        self.eps = np.finfo(np.float32).eps\n",
    "\n",
    "\n",
    "    def _init_params(self):\n",
    "        \"\"\"\n",
    "        随机初始化模型参数w\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        w = {}\n",
    "        for key in self.hat_p_x_y.keys():\n",
    "            w[key] = np.random.rand()\n",
    "        self.params['w'] = w\n",
    "\n",
    "    def _rebuild_X(self, X):\n",
    "        \"\"\"\n",
    "        为了自变量的差异化处理，重新命名自变量\n",
    "        :param X: 原始自变量\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X_result = []\n",
    "        for x in X:\n",
    "            X_result.append([y_s + '_' + x_s for x_s, y_s in zip(x, self.X_columns)])\n",
    "        return X_result\n",
    "\n",
    "    def _build_mapping(self, X, Y):\n",
    "        \"\"\"\n",
    "        求取经验分布，参照公式(1)(2)\n",
    "        :param X: 训练样本的输入值\n",
    "        :param Y: 训练样本的输出值\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for x, y in zip(X, Y):\n",
    "            for x_s in x:\n",
    "                if x_s in self.hat_p_x.keys():\n",
    "                    self.hat_p_x[x_s] += 1\n",
    "                else:\n",
    "                    self.hat_p_x[x_s] = 1\n",
    "                if (x_s, y) in self.hat_p_x_y.keys():\n",
    "                    self.hat_p_x_y[(x_s, y)] += 1\n",
    "                else:\n",
    "                    self.hat_p_x_y[(x_s, y)] = 1\n",
    "\n",
    "        self.hat_p_x = {key: count / self.N for key, count in self.hat_p_x.items()}\n",
    "        self.hat_p_x_y = {key: count / self.N for key, count in self.hat_p_x_y.items()}\n",
    "\n",
    "    def _cal_E_hat_p(self):\n",
    "        \"\"\"\n",
    "        计算特征函数f(x,y)关于经验分布hatP(X,Y)的期望值，参照公式(3)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.E_hat_p = self.hat_p_x_y\n",
    "\n",
    "\n",
    "    def _cal_E_p(self, X):\n",
    "        \"\"\"\n",
    "        计算特征函数f(x,y)关于模型P(X|Y)与经验分布hatP(X)的期望值，参照公式(4)\n",
    "        :param X:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for key in self.params['w'].keys():\n",
    "            self.E_p[key] = 0\n",
    "        for x in X:\n",
    "            p_y_x = self._cal_prob(x)\n",
    "            for x_s in x:\n",
    "                for (p_y_x_s, y) in p_y_x:\n",
    "                    if (x_s, y) not in self.E_p.keys():\n",
    "                        continue\n",
    "                    self.E_p[(x_s, y)] += (1/self.N) * p_y_x_s\n",
    "\n",
    "    def _cal_p_y_x(self, x, y):\n",
    "        \"\"\"\n",
    "        计算模型条件概率值，参照公式(9)的指数部分\n",
    "        :param x: 单个样本的输入值\n",
    "        :param y: 单个样本的输出值\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        sum = 0.0\n",
    "        for x_s in x:\n",
    "            sum += self.params['w'].get((x_s, y), 0)\n",
    "        return np.exp(sum), y\n",
    "\n",
    "\n",
    "    def _cal_prob(self, x):\n",
    "        \"\"\"\n",
    "        计算模型条件概率值，参照公式(9)\n",
    "        :param x: 单个样本的输入值\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        p_y_x = [(self._cal_p_y_x(x, y)) for y in self.label]\n",
    "        sum_y = np.sum([p_y_x_s for p_y_x_s, y in p_y_x])\n",
    "        return [(p_y_x_s / sum_y, y) for p_y_x_s, y in p_y_x]\n",
    "\n",
    "\n",
    "    def fit(self, X, X_columns, Y, label, max_iter=20000):\n",
    "        \"\"\"\n",
    "        模型训练入口\n",
    "        :param X: 训练样本输入值\n",
    "        :param X_columns: 训练样本的columns\n",
    "        :param Y: 训练样本的输出值\n",
    "        :param label: 训练样本的输出空间\n",
    "        :param max_iter: 最大训练次数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.N = len(X)\n",
    "        self.label = label\n",
    "        self.X_columns = X_columns\n",
    "\n",
    "        X = self._rebuild_X(X)\n",
    "\n",
    "        self._build_mapping(X, Y)\n",
    "\n",
    "        self._cal_E_hat_p()\n",
    "\n",
    "        self._init_params()\n",
    "\n",
    "        for iter in range(max_iter):\n",
    "\n",
    "            self._cal_E_p(X)\n",
    "\n",
    "            for key in self.params['w'].keys():\n",
    "                sigma = self.lr * np.log(self.E_hat_p.get(key, self.eps) / self.E_p.get(key, self.eps))\n",
    "                self.params['w'][key] += sigma\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        预测结果\n",
    "        :param X: 样本\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X = self._rebuild_X(X)\n",
    "        result_list = []\n",
    "\n",
    "        for x in X:\n",
    "            max_result = 0\n",
    "            y_result = self.label[0]\n",
    "            p_y_x = self._cal_prob(x)\n",
    "            for (p_y_x_s, y) in p_y_x:\n",
    "                if p_y_x_s > max_result:\n",
    "                    max_result = p_y_x_s\n",
    "                    y_result = y\n",
    "            result_list.append((max_result, y_result))\n",
    "        return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_my_model():\n",
    "    data_set = [['youth', 'no', 'no', '1', 'refuse'],\n",
    "               ['youth', 'no', 'no', '2', 'refuse'],\n",
    "               ['youth', 'yes', 'no', '2', 'agree'],\n",
    "               ['youth', 'yes', 'yes', '1', 'agree'],\n",
    "               ['youth', 'no', 'no', '1', 'refuse'],\n",
    "               ['mid', 'no', 'no', '1', 'refuse'],\n",
    "               ['mid', 'no', 'no', '2', 'refuse'],\n",
    "               ['mid', 'yes', 'yes', '2', 'agree'],\n",
    "               ['mid', 'no', 'yes', '3', 'agree'],\n",
    "               ['mid', 'no', 'yes', '3', 'agree'],\n",
    "               ['elder', 'no', 'yes', '3', 'agree'],\n",
    "               ['elder', 'no', 'yes', '2', 'agree'],\n",
    "               ['elder', 'yes', 'no', '2', 'agree'],\n",
    "               ['elder', 'yes', 'no', '3', 'agree'],\n",
    "               ['elder', 'no', 'no', '1', 'refuse'],\n",
    "               ]\n",
    "    columns = ['age', 'working', 'house', 'credit_situation', 'label']\n",
    "    X = [i[:-1] for i in data_set]\n",
    "    X_columns = columns[:-1]\n",
    "    Y = [i[-1] for i in data_set]\n",
    "    print(X)\n",
    "    print(Y)\n",
    "\n",
    "    my = MyMaxEntropy()\n",
    "    train_X = X[:12]\n",
    "    test_X = X[12:]\n",
    "    train_Y = Y[:12]\n",
    "    test_Y = Y[12:]\n",
    "    my.fit(train_X, X_columns, train_Y, label=['refuse', 'agree'])\n",
    "\n",
    "    print(my.params)\n",
    "\n",
    "    pred_Y= my.predict(test_X)\n",
    "    print('result: ')\n",
    "    print('test: ', test_Y)\n",
    "    print('pred: ', pred_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['youth', 'no', 'no', '1'], ['youth', 'no', 'no', '2'], ['youth', 'yes', 'no', '2'], ['youth', 'yes', 'yes', '1'], ['youth', 'no', 'no', '1'], ['mid', 'no', 'no', '1'], ['mid', 'no', 'no', '2'], ['mid', 'yes', 'yes', '2'], ['mid', 'no', 'yes', '3'], ['mid', 'no', 'yes', '3'], ['elder', 'no', 'yes', '3'], ['elder', 'no', 'yes', '2'], ['elder', 'yes', 'no', '2'], ['elder', 'yes', 'no', '3'], ['elder', 'no', 'no', '1']]\n",
      "['refuse', 'refuse', 'agree', 'agree', 'refuse', 'refuse', 'refuse', 'agree', 'agree', 'agree', 'agree', 'agree', 'agree', 'agree', 'refuse']\n",
      "{'w': {('age_youth', 'refuse'): 0.6607178829713231, ('working_no', 'refuse'): 0.22746736807343207, ('house_no', 'refuse'): 0.9442476263823766, ('credit_situation_1', 'refuse'): 0.9173418028251692, ('credit_situation_2', 'refuse'): 0.11346457089398976, ('age_youth', 'agree'): 0.4080508219989123, ('working_yes', 'agree'): 1.3242717074181272, ('house_no', 'agree'): -0.2820670204687476, ('credit_situation_2', 'agree'): 0.48715978394318976, ('house_yes', 'agree'): 0.6647820446536167, ('credit_situation_1', 'agree'): 0.28199472230372313, ('age_mid', 'refuse'): 0.645008050394161, ('age_mid', 'agree'): 0.24986661130764587, ('working_no', 'agree'): 0.2834950686344172, ('credit_situation_3', 'agree'): 1.239710329315179, ('age_elder', 'agree'): 0.8890575225362609}}\n",
      "result: \n",
      "test:  ['agree', 'agree', 'refuse']\n",
      "pred:  [(0.7958750339709215, 'agree'), (0.9026238777607725, 'agree'), (0.7143440316123404, 'refuse')]\n"
     ]
    }
   ],
   "source": [
    "run_my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glmnet\n",
      "  Downloading glmnet-2.2.1.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m215.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/7h/dvwccw_s5f93pgp_lnn__6_40000gn/T/pip-install-zudaj501/glmnet_2d3989bfe0a94a1c9823952fa4c980d9/setup.py:14: DeprecationWarning:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "  \u001b[31m   \u001b[0m   of the deprecation of `distutils` itself. It will be removed for\n",
      "  \u001b[31m   \u001b[0m   Python >= 3.12. For older Python versions it will remain present.\n",
      "  \u001b[31m   \u001b[0m   It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "  \u001b[31m   \u001b[0m   For more details, see:\n",
      "  \u001b[31m   \u001b[0m     https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   from numpy.distutils.core import Extension, setup\n",
      "  \u001b[31m   \u001b[0m /Users/chenyangkang/miniforge3/lib/python3.9/site-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m error in glmnet setup command: 'python_requires' must be a string containing valid version specifiers; Invalid specifier: '>=3.6.*'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install glmnet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
